{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbsc3/fROxjiYAkZNT0Fsx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahika-jain/vprofile-project/blob/vp-rem/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omkgBiWWPUf3",
        "outputId": "c3a55024-24bf-46dd-f8c9-e12a720922e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "The predicted class for the new video is: fights\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "CLASS_NAME=[\"fights\",\"nofights\"]\n",
        "# Load the trained model\n",
        "loaded_model = load_model('model.h5')\n",
        "IMAGE_HEIGHT,IMAGE_WIDTH=64,64\n",
        "SEQUENCE_LENGTH=20\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def frame_extract(video_path):\n",
        "  FRAME_LIST=[]\n",
        "  video_reader=cv2.VideoCapture(video_path)\n",
        "  video_frame_count=int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  skip_frames_window=max(int(video_frame_count/SEQUENCE_LENGTH),1)\n",
        "  for frame_counter in range(SEQUENCE_LENGTH):\n",
        "    video_reader.set(cv2.CAP_PROP_POS_FRAMES,frame_counter*skip_frames_window)\n",
        "    success,frame=video_reader.read()\n",
        "\n",
        "    if not success:\n",
        "        break\n",
        "    resized_frame=cv2.resize(frame,(IMAGE_HEIGHT,IMAGE_WIDTH))\n",
        "    normalise_frame=resized_frame/255\n",
        "    FRAME_LIST.append(normalise_frame)\n",
        "  video_reader.release()\n",
        "  return FRAME_LIST\n",
        "# Define a function to preprocess new video\n",
        "def preprocess_new_video(video_path):\n",
        "    new_frames = frame_extract(video_path)\n",
        "    new_features = np.array([new_frames])\n",
        "    return new_features\n",
        "\n",
        "# Make predictions on new video\n",
        "new_video_path = \"/content/newfi15.avi\"\n",
        "new_features = preprocess_new_video(new_video_path)\n",
        "\n",
        "# Make predictions\n",
        "new_predictions = loaded_model.predict(new_features)\n",
        "\n",
        "# Post-process predictions (example: convert to class labels)\n",
        "predicted_labels = np.argmax(new_predictions, axis=1)\n",
        "predicted_class = CLASS_NAME[predicted_labels[0]]\n",
        "\n",
        "print(f\"The predicted class for the new video is: {predicted_class}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R5x2C-MOP4MN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}